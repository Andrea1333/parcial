<!doctype html>
<html lang="es">
<head>
<link rel="stylesheet" type="text/css" href="base.css" />
<link rel="stylesheet" type="text/css" href="content.css" />
<link rel="stylesheet" type="text/css" href="nav.css" />
<meta http-equiv="content-type" content="text/html;  charset=utf-8" />
<title>La Máquina Moral | Ética Utilitarista </title>
<link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<meta name="author" content="Andrea Riva" />
<link rel="license" type="text/html" href="http://creativecommons.org/licenses/by-sa/4.0/" />
<meta name="generator" content="eXeLearning 2.9 - exelearning.net" />
<!--[if lt IE 9]><script type="text/javascript" src="exe_html5.js"></script><![endif]-->
<script type="text/javascript" src="exe_jquery.js"></script>
<script type="text/javascript" src="common_i18n.js"></script>
<script type="text/javascript" src="common.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
</head>
<body class="exe-web-site" id="exe-node-6"><script type="text/javascript">document.body.className+=" js"</script>
<div id="content">
<p id="skipNav"><a href="#main" class="sr-av">Saltar la navegación</a></p>
<header id="header" ><div id="headerContent">Ética Utilitarista</div></header>
<nav id="siteNav">
<ul>
   <li><a href="index.html" class="daddy main-node">Inicio</a></li>
   <li><a href="antecedente.html" class="no-ch">Antecedente</a></li>
   <li class="current-page-parent"><a href="stuart_mill.html" class="current-page-parent daddy">Stuart Mill</a>
   <ul>
      <li><a href="dilema_tico.html" class="no-ch">Dilema ético</a></li>
      <li id="active"><a href="la_mquina_moral.html" class="active no-ch">La Máquina Moral</a></li>
      <li><a href="test.html" class="no-ch">Test</a></li>
   </ul>
   </li>
   <li><a href="bibliografa.html" class="no-ch">Bibliografía</a></li>
</ul>
</nav>
<div id='topPagination'>
<nav class="pagination noprt">
<a href="dilema_tico.html" class="prev"><span><span>&laquo; </span>Anterior</span></a> <span class="sep">| </span><a href="test.html" class="next"><span>Siguiente<span> &raquo;</span></span></a>
</nav>
</div>
<div id="main-wrapper">
<section id="main">
<header id="nodeDecoration"><h1 id="nodeTitle">La Máquina Moral</h1></header>
<article class="iDevice_wrapper textIdevice" id="id8">
<div class="iDevice emphasis0" >
<div id="ta8_129_2" class="block iDevice_content">
<div class="exe-text"><p style="text-align: justify;"><br /><span style="font-family: arial, helvetica, sans-serif;">En 2016, un grupo de investigadores del MIT Media Lab crearon ‘Moral Machine’, un juego de ética que planteaba a los participantes el tipo de cuestiones éticas que, dentro de poco, tendrán que resolver los vehículos sin conductor. Han reunido más de cuatro millones de respuestas y ahora tenemos los primeros resultados.</span></p>
<p><a href="https://www.moralmachine.net/hl/es">VER</a></p>
<p> </p>
<p style="text-align: center;"><span style="font-size: 18pt;">Acerca de la Máquina Moral</span></p>
<p style="text-align: justify;"><br /> <br /><span style="font-family: arial, helvetica, sans-serif;">Desde los vehículos autónomos en vías públicas hasta los cohetes reutilizables no tripulados que aterrizan en buques autónomos, las máquinas inteligentes están apoyando o totalmente asumiendo actividades humanas cada vez más complejas a un ritmo creciente. La mayor autonomía dada a las máquinas inteligentes en estos papeles, puede llevar a situaciones en las que éstas tienen que tomar decisiones de manera autónoma, que afectan a la integridad física de humanos. Esto requiere, no sólo una comprensión más clara de cómo los seres humanos toman tales decisiones, sino también una comprensión más clara de cómo los seres humanos perciben la inteligencia de la máquina tomando tales decisiones.</span></p>
<p style="text-align: justify;"><span style="font-family: arial, helvetica, sans-serif;">Estudios científicos recientes han puesto este asunto en los medios de comunicación y el discurso público. Este sitio web pretende profundizar en la discusión proporcionando una plataforma para: </span><span style="font-family: arial, helvetica, sans-serif;"><strong>1)</strong> Construir una imagen multitudinaria (usando "crowdsourcing") de la opinión de los humanos sobre cómo las máquinas deben tomar decisiones cuando se enfrentan a dilemas morales; y </span><span style="font-family: arial, helvetica, sans-serif;"><strong>2)</strong> permitir la construcción y discusión de posibles escenarios con implicaciones morales por una multitud de individuos.</span></p></div>
</div>
</div>
</article>
<div id="packageLicense" class="cc cc-by-sa">
<p><span>Obra publicada con</span> <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Licencia Creative Commons Reconocimiento Compartir igual 4.0</a></p>
</div>
</section>
</div>
<div id='bottomPagination'>
<nav class="pagination noprt">
<a href="dilema_tico.html" class="prev"><span><span>&laquo; </span>Anterior</span></a> <span class="sep">| </span><a href="test.html" class="next"><span>Siguiente<span> &raquo;</span></span></a>
</nav>
</div>
</div>
<p id="made-with-eXe"><a href="https://exelearning.net/" target="_blank" rel="noopener"><span>Creado con eXeLearning<span> (Ventana nueva)</span></span></a></p><script type="text/javascript" src="_style_js.js"></script></body></html>